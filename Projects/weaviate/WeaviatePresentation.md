# Weaviate - Vector Database
## Blu Medina

### What is a vector database? 
A vector database indexes, stores and provides access to any type of data, whether it is structured or unstructured (i.e. text or images) alongside its vector embeddings. It's vector embeddings are the data's numerical representation. This allows users to find a retrieve similar objects quickly at scale. 

### How is a vector database (Weaviate) different from a relational database (Postgres)
|Feature | Weaviate (Vector Database) | PostgreSQL (Relational Database) |
|--------|----------------------------|----------------------------------|
| **Database Type** | NoSQL, vector-native | SQL, relational |
| **Data Model**| Schema-flexible (JSON-like objects and vectors) | Fixed schema (tables, rows, and columns) |
| **Primary Strength** | Semantic search, AI/LLM integration | ACID transactions, complex joins|
| **Search Capability** | Vector similarity, hybrid (keyword + vector) search | Exact matches|
| **Scalability** | Horizontally scalable (distributed) | Vertical scaling |
| **Transactions** | Limited (eventual consistency) | Full ACID compliance|
| **Use Cases**	| Semantic search, RAG (Retrieval-Augmented Generation), AI-powered apps | Transactional systems, Reporting/analytics, Traditional CRUD|

### What types of projects should Weaviate be used for? 
Since Weaviate is a vector database and excels in semantic search, recommendation systems, and AI powered applications. Therefore these are some of the best projects to use Weaviate for:
- Semantic Search Engines
    - Ex: Online shopping search ("Find shoes like these but cheaper")
- Recommendation Systems
    - Ex: being able to tell which users liked X movie and Y book as a recommendation
- Chatbots
    - Ex: Q&A - AI customer service 
- Image & Multimedia Search
    - Ex: Finding similar images/videos using vector embeddings ("Find furniture with this style")
- And More!


## Understanding Demo Code

Within `connect.py` we're given this code:
```
client = weaviate.connect_to_weaviate_cloud(
    cluster_url=weaviate_url,
    auth_credentials=Auth.api_key(weaviate_api_key),
)

print(client.is_ready())  
```
This sets the variable `client` to check if it can connect to my Weaviate could cluster using my REST Endpoint and Admin API key. If it can connect without any problems, the line `print(client.is_ready())` will print `True`.

<br>

In a new file called `collection.py`, we add onto the code within `connect.py` to create a collection. A collection in Weaviate is a structured group of data objects that share the same schema. 
```
questions = client.collections.create(
    name="Question",
    vectorizer_config=Configure.Vectorizer.text2vec_weaviate(),
    generative_config=Configure.Generative.cohere()             
)
```
The code calls Weaviate to create a new collection called question. It then uses this line - `vectorizer_config=Configure.Vectorizer.text2vec_weaviate()` - to configure how text data will be converted into vector embeddings using Weaviates built in text2vec module (similar to Word2Vec from the beginning of the year!). This line - `generative_config=Configure.Generative.cohere()` - sets up generative AI capabilities using Cohere's generative AI model which will be integrated later.

<br>

In `import.py` we build on past code in `connect.py` and `collection.py`. We first load JSON data, which can be an outside URL, or it can be your own file. I personally messed with my own JSON data, generated by DeepSeek.
```
with open("data/jeopardy.json", "r") as dataj:
    data = json.load(dataj)

```
This just opens the `jeopardy.json` file and then parses the JSON file into a Python dictionary. Once it reads and parses the file, it accesses the Weaviate collection (created in the `connect.py` file) using this line `questions = client.collections.get("Question")`. 

<br>

Then we batch import data with this code: 
```
with questions.batch.fixed_size(batch_size=200) as batch:
    for category in data["categories"]:
        category_name = category["name"]
        for question_data in category["questions"]:
            batch.add_object(
                {
                    "answer": question_data["answer"],
                    "question": question_data["question"],
                    "category": category_name,
                    "value": question_data["value"]  
                }
            )
            if batch.number_errors > 10:
                print("Batch import stopped due to excessive errors.")
                break
```
The code above starts a batch import, which is efficient for large datasets, with a batch size of 200. Then it loops through each `category` on the JSON file. Then for each question in `category["questions"]` it adds it to Weaviate with a `answer`,`question`,`category`, and `value`. The end of the batch import stops it if more than 10 errors occur. 

<br>

Within `query.py` we print our first queries using this code (which was built on top of all other code before):
```
questions = client.collections.get("Question")

response = questions.query.near_text(
    query="science",
    limit=2,
)

for obj in response.objects:
    print(json.dumps(obj.properties, indent=2))
```
The code connects to the collection which we just loaded data into from `import.py`. Then we set a variable called response which preforms a semantic search to find objects similar to the word science. Essentially, the code coverts the query (which in this case is `science`) to a vector using the collections vectorizer, then compares this against other vectors in the collection, then returns the top 2 results. 

<br>

Now, as a final little trick we will use a generative AI model (Cohere) to essentially create a tweet using a query. Within our file `rag.py` we use Retrieval Augmented Generation (RAG), aka generative search, to combine the power of generative AI models (such as Large Language Models (LLMs)) with databases! RAG works by prompting a large language model with a combo of user query and data retrieved from the database. Here is a helpful diagram provided by Weaviates quickstart tutorials: 

<img src="media/diagram.png" alt="RAG diagram">

Now for the code:
```
client = weaviate.connect_to_weaviate_cloud(
    cluster_url=weaviate_url,                                    
    auth_credentials=Auth.api_key(weaviate_api_key),             
    headers={"X-Cohere-Api-Key": cohere_api_key},           
)

questions = client.collections.get("Question")

response = questions.generate.near_text(
    query="science",
    limit=2,
    grouped_task="Write a tweet with emojis about these facts."
)

print(response.generated)  
```

It uses the same connection code that we originally mentioned from `connect.py` that we have been using in every file, except now we are connecting to Coheres API using one of their trial keys. Then we connect to the collection, which has data loaded into it from `import.py`. 
Now, remember this little line of code - `generative_config=Configure.Generative.cohere()` - from the `collection.py` file? This line of code allows for the collection to use generative AI models such as cohere. Then we follow the same query structure as `query.py` except we give the LLM a task. Then we print it to get a fun 'tweet' containing emojis. 
